{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94e10ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from numpy.linalg import matrix_rank\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA as SKPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bede1071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aff5d1",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook is the self-assigned final project for a Coursera course that I took entitled *Mathematics for Machine Learning: PCA* during the Spring 2023 term.  In an effort to digest the material learned in this course and expand upon it, I decided to write this work.\n",
    "\n",
    "With the exception of the first and last four code blocks, the work is entirely my own.  Most of the functions herein were assigned in the aforementioned course, except for the reconstructError, compEquiv1, and compEquiv2 functions.  These functions display my penchant for vectorization.\n",
    "\n",
    "The intention of this notebook and the course is to give intuition on PCA.  The PCA algorithm herein is by no means the most efficient or versatile PCA algorithm.  This is because it does not use the SVD to reduce the data to its most salient components and instead embeds the data in a lower-dimensional subspace.  For a robust PCA algorithm, consider the Sci-Kit Learn PCA algorithm found [here](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html).\n",
    "\n",
    "This notebook assumes that the reader is comfortable with the material in a standard first course in Linear Algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc718fb",
   "metadata": {},
   "source": [
    "#### Notation\n",
    "\n",
    "We start with a data set $\\mathcal{D} \\in \\mathbb{R}^{N \\times F}$.  That is, $\\mathcal{D}$ has $N$ rows and $F$ columns and all entries $\\mathcal{D}_{ij}$ are real numbers.  We think of each row as an individual observation vector whose components are observations from each of the $F$ features.\n",
    "\n",
    "Since it is customary to think of vectors as *column vectors*, we will most often work with the transpose of $\\mathcal{D}$ and give it the special name $X=\\mathcal{D}^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b293c28a",
   "metadata": {},
   "source": [
    "### Symmetric Matrices\n",
    "\n",
    "A matrix $S\\in \\mathbb{R}^{n\\times n}$ is said to be *symmetric*, if $S=S^T$.  The following function produces a randomly generted symmetric matrix with dimensions $M\\times M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "42147419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randSym(M):\n",
    "    \"\"\"Generate a random symmetric M by M matrix \n",
    "        Args: \n",
    "            M: the dimensions of the matrix\n",
    "            \n",
    "        Returns: symmetric ndarray with shape (M,M)\"\"\"\n",
    "    A = np.random.randint(low=0, high=100, size=(M,M)) \n",
    "    return (A+A.T)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea865bf",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b6d5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73. , 53. , 45. ,  9.5, 47.5],\n",
       "       [53. , 73. , 37. , 65.5, 53.5],\n",
       "       [45. , 37. , 10. , 27.5, 78. ],\n",
       "       [ 9.5, 65.5, 27.5, 86. , 55. ],\n",
       "       [47.5, 53.5, 78. , 55. , 38. ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randSym(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f63d7f",
   "metadata": {},
   "source": [
    "$\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62d20fa",
   "metadata": {},
   "source": [
    "### Mean-Centered Data\n",
    "\n",
    "The theoretic results that are applied in this notebook assume that our datasets $\\mathcal{D}$ are *mean-centered*.  This means that the mean of each column of $\\mathcal{D}$ is $0$.  The following function accomplishes this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7aa5f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    \"\"\"Normalize the given dataset X to have zero mean.\n",
    "    Args:\n",
    "        data: ndarray, dataset of shape (N,D) where D is the dimension of the data,\n",
    "           and N is the number of datapoints\n",
    "    \n",
    "    Returns:\n",
    "        dataBar: tuple of ndarray, dataBar is the normalized dataset\n",
    "        with mean 0; mu is the sample mean of the dataset.\n",
    "    \"\"\"\n",
    "    mu = np.mean(data, axis=0)\n",
    "    dataBar = data-mu\n",
    "    return dataBar, mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a7d0e7",
   "metadata": {},
   "source": [
    "### Variance and Covariance\n",
    "\n",
    "Choose two columns of $\\mathcal{D}$ and label them $x$ and $y$.  The *Covariance* of $x$ and $y$ is the quantity $$\\text{cov}(x,y)=\\frac{1}{N}\\cdot \\sum(x_i-\\mu_x)(y_i-\\mu_y)$$  The *variance* of a single column, say $x$, is defined as $cov(x,x)$.  \n",
    "\n",
    "When the data set is mean centered, the formula above reduces to $\\text{cov}(x,y)=\\frac{1}{N}\\cdot \\sum x_i \\cdot y_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be00ea8",
   "metadata": {},
   "source": [
    "#### Covariance Matrix\n",
    "\n",
    "Given a data set $\\mathcal{D} \\in \\mathbb{R}^{N \\times F}$ with features $x_1,...,x_F$, the *Covariance Matrix* of $\\mathcal{D}$ is the matrix with entries $\\text{cov}(x_i,x_j)$.  We shall denote the covariance matrix of a data set $\\mathcal{D}$ as $S=\\text{cov}(\\mathcal{D})$.  Since $cov(x_i,x_j)=cov(x_j,x_i)$, it is seen that $\\text{cov}(\\mathcal{D})$ is a *symmetric* matrix whose ith diagonal entry gives the covariance of feature $x_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f037b12",
   "metadata": {},
   "source": [
    "Recalling that $X=\\mathcal{D}^T$, we see that $S=\\text{cov}(\\mathcal{D})=\\frac{1}{N}XX^T \\text{,}$ assuming that $\\mathcal{D}$ is mean centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46af917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov(D):\n",
    "    \"\"\"Compute the sample covariance for a dataset.\n",
    "    Args:\n",
    "        D: ndarray of shape (N, D) representing the dataset.\n",
    "        N is the size of the dataset (the number of data points) \n",
    "        and D is the dimensionality of each data point.\n",
    "    Returns:\n",
    "        ndarray: ndarray with shape (D, D), the sample covariance of the dataset D.\n",
    "    \"\"\"\n",
    "    N=D.shape[0]\n",
    "    mu=np.mean(D, axis=0)\n",
    "    return ((D-mu).T@(D-mu))/N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e44064",
   "metadata": {},
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ab2b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [2, 1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D=np.array([[0, 1, 2], [2, 1, 0]])\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4a1578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0., -1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [-1.,  0.,  1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54aa0d",
   "metadata": {},
   "source": [
    "$\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489236d",
   "metadata": {},
   "source": [
    "### Orthonormal Bases\n",
    "\n",
    "A basis $b_1,b_2,...,b_n$ for $\\mathbb{R}^n$ is said to be *orthonormal* if $b_i^Tb_j=0$ when $i\\neq j$ and $b_i^Tb_j=1$, when $i=j$.  This implies that $||b_i||_2=1$ for all $i$.\n",
    "\n",
    "A nice way to generate an orthonormal basis for $\\mathbb{R}^n$ is to use the *Spectral Theorem* and the function randSym defined above.\n",
    "\n",
    "##### Spectral Theorem\n",
    "If $S\\in \\mathbb{R}^{n \\times n}$ is symmetric ($S=S^T$), then there exists an orthonormal basis for $\\mathbb{R}^n$ consisting of eigenvectors of $S$ and all eigenvalues of $S$ are real numbers.\n",
    "\n",
    "Thus, it is likely (but not guarenteed) that the following function will produce an orthonormal basis for $\\mathbb{R}^n$ when the argument $A$ is a symmetric matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9668167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eig(A):\n",
    "    \"\"\"Compute the eigenvalues and corresponding eigenvectors\n",
    "        for the matrix A.\n",
    "    Args:\n",
    "        A: ndarray of shape (n,n)\n",
    "\n",
    "    Returns:\n",
    "        (eigvals, eigvecs): ndarray, the eigenvalues and eigenvectors sorted in descending\n",
    "        order of the eigenvalues and each eigenvector has Euclidean Norm 1\n",
    "    \"\"\"\n",
    "    \n",
    "    eigvals, eigvecs = np.linalg.eig(A)\n",
    "    \n",
    "    args=np.flip(np.argsort(eigvals))\n",
    "    \n",
    "    return eigvals[args], eigvecs[:, args]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152877a0",
   "metadata": {},
   "source": [
    "##### Example\n",
    "\n",
    "We begin with a symmetric matrix $S=S^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1b99773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 2,  6,  7,  8,  9],\n",
       "       [ 3,  7, 10, 11, 12],\n",
       "       [ 4,  8, 11, 13, 14],\n",
       "       [ 5,  9, 12, 14, 15]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S=np.array([[1,2,3,4,5],[2,6,7,8,9],[3,7,10,11,12],[4,8,11,13,14],[5,9,12,14,15]])\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b4ff672",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals, B = eig(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf2c1cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16657759, -0.51923398, -0.2622205 , -0.29272354,  0.74040618],\n",
       "       [ 0.34610435,  0.73629348, -0.5205591 ,  0.01176247,  0.25877317],\n",
       "       [ 0.4660024 ,  0.24779322,  0.75652334, -0.32514414,  0.20831227],\n",
       "       [ 0.53924491, -0.23445474,  0.07392338,  0.80337432,  0.05805977],\n",
       "       [ 0.58695859, -0.26813704, -0.28716962, -0.40378901, -0.58143804]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d3cf0",
   "metadata": {},
   "source": [
    "Lets check that the eigenvectors of $S$ form an orthonormal basis for $\\mathbb{R}^5$.\n",
    "\n",
    "First, we check that the eigenvector matrix $B$ is full rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1648e9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_rank(B, hermitian=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b36758",
   "metadata": {},
   "source": [
    "Next, we check that the columns of $B$ are orthonormal.  To do this, we use the fact that the columns of $B$ are orthonormal, if $B^TB=I$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44f7710d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(B.T@B, np.eye(5),atol=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8088e0",
   "metadata": {},
   "source": [
    "$\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f3c849",
   "metadata": {},
   "source": [
    "### Orthogonal Projections\n",
    "\n",
    "Given a basis $b_1,...,b_F$ for $\\mathbb{R}^F$, we can project a vector $x\\in \\mathbb{R}^F$ onto the $m$-dimensional subspace $U$ of $\\mathbb{R}^F$ that is spanned by the first $m$ basis vectors $b_1,...,b_m$ (m<F).  That is, $U=$ span$\\{b_1,...,b_m\\}$.  \n",
    "\n",
    "We use $\\hat{x}$ to denote the projection of $x$ onto $U$ so that the vector from $U$ to $x$ is orthogonal to all vectors of $U$.  In other words, $(x-\\hat{x})^Tu=0$, for all $u\\in U$.  Using the *normal equations*, it can be shown that $\\hat{x}=B(B^TB)^{-1}B^Tx$, where $B=(b_1|...|b_m)$. The matrix $B(B^TB)^{-1}B^T$ is called a *projection* matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380aa789",
   "metadata": {},
   "source": [
    "#### Orthonormal Projections\n",
    "\n",
    "When the basis $b_1,...,b_F$ is *orthonormal*, $B^TB=I$ and the projection matrix simplifies to $BB^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d07faf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(x, B, m):\n",
    "    \"\"\"Compute the projection onto the space spanned by the first m columns of B\n",
    "    Args:\n",
    "        x: ndarray of dimension (D, 1), the vector to be projected\n",
    "        B: ndarray of dimension (D, M), the basis for the subspace\n",
    "        m: the number of basis vectors in B to use\n",
    "    \n",
    "    Returns:\n",
    "        projection of x onto the subspace spanned by the columns of B; size (D, 1)\n",
    "    \"\"\"\n",
    "    B=B[:,:m]\n",
    "    P=B@np.linalg.inv((B.T)@B)@B.T\n",
    "\n",
    "    return P@x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55c02e",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "The vectors $b_1=\\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    1 \\\\\n",
    "    0 \\\\\n",
    "\\end{pmatrix}$, $b_2=\\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    0 \\\\\n",
    "    1 \\\\\n",
    "\\end{pmatrix}$, and $b_3=\\begin{pmatrix}\n",
    "    0 \\\\\n",
    "    1 \\\\\n",
    "    1 \\\\\n",
    "\\end{pmatrix}$ form a basis for $\\mathbb{R}^3$.  We project the vector $x=\\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    1 \\\\\n",
    "    1 \\\\\n",
    "\\end{pmatrix}$ onto the subspace spanned by $b_1$ and $b_2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a59f6b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=np.array([[1,1,0],[1,0,1],[0,1,1]])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "445d3243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9cd52dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([[1,1,1]]).T\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe118004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.33333333],\n",
       "       [0.66666667],\n",
       "       [0.66666667]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xHat=project(x,B,2)\n",
    "xHat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f6c7a",
   "metadata": {},
   "source": [
    "Our work above shows that $\\hat{x}=\\begin{pmatrix}\n",
    "    4/3 \\\\\n",
    "    2/3 \\\\\n",
    "    2/3 \\\\\n",
    "\\end{pmatrix}=2/3\\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    1 \\\\\n",
    "    0 \\\\\n",
    "\\end{pmatrix}+2/3\\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    0 \\\\\n",
    "    1 \\\\\n",
    "\\end{pmatrix}=\\frac{2}{3}\\cdot b_1+\\frac{2}{3}\\cdot b_2$.  In other words, $\\hat{x}$ lives in the plane spanned by $b_1$ and $b_2$.\n",
    "\n",
    "$\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340394b1",
   "metadata": {},
   "source": [
    "##### Example\n",
    "\n",
    "Above, we found the eigenvalues and eigenvectors for the symmetric matrix $S$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "756cf56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 2,  6,  7,  8,  9],\n",
       "       [ 3,  7, 10, 11, 12],\n",
       "       [ 4,  8, 11, 13, 14],\n",
       "       [ 5,  9, 12, 14, 15]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S=np.array([[1,2,3,4,5],[2,6,7,8,9],[3,7,10,11,12],[4,8,11,13,14],[5,9,12,14,15]])\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff422a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16657759, -0.51923398, -0.2622205 , -0.29272354,  0.74040618],\n",
       "       [ 0.34610435,  0.73629348, -0.5205591 ,  0.01176247,  0.25877317],\n",
       "       [ 0.4660024 ,  0.24779322,  0.75652334, -0.32514414,  0.20831227],\n",
       "       [ 0.53924491, -0.23445474,  0.07392338,  0.80337432,  0.05805977],\n",
       "       [ 0.58695859, -0.26813704, -0.28716962, -0.40378901, -0.58143804]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals, B = eig(S)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2269f",
   "metadata": {},
   "source": [
    "We project the vector $x=\\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    1 \\\\\n",
    "    1 \\\\\n",
    "    1\\\\\n",
    "    1\\\\\n",
    "\\end{pmatrix}$ onto the subspace spanned by the first three eigenvectors $b_1$, $b_2$, and $b_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1183a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "B=B[: , :3]\n",
    "x=np.array([[1,1,1,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0272deb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae7d765e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43302501],\n",
       "       [0.825399  ],\n",
       "       [0.79034206],\n",
       "       [1.12619331],\n",
       "       [1.31437907]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xHat=project(x,B)\n",
    "xHat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0fc1a7",
   "metadata": {},
   "source": [
    "$\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f0f2d",
   "metadata": {},
   "source": [
    "### Projection Error\n",
    "\n",
    "Given a mean-centered data set $\\mathcal{D}$ (with $N$ rows and $F$ columns) and an orthonormal basis $b_1,b_2,...,b_F$ for $\\mathbb{R}^F$, we can choose any $m<F$ of these basis vectors and form (with a possible relabelling of the subscripts) the matrix $B=(b_1|b_2|...|b_m)$.  Using the projection $BB^Tx$, we can then project each of the rows $x_i$ of $\\mathcal{D}$ onto the lower dimensional subspace (of $\\mathbb{R}^F$) spanned by the vectors $b_1, b_2, ... , b_m$.  We call this lower dimensional subspace the *principal subspace* and give it the special symbol $U$.  In symbols, $U=\\text{span}(b_1,b_2,...,b_m)$.\n",
    "\n",
    "##### How much information is lost when all $x_i$ are projected onto U?\n",
    "\n",
    "To answer this question, we measure the loss of information using the *average squared reconstruction error* $$J=\\frac{1}{N}\\cdot \\sum_{i=1}^N||x_i-\\hat{x_i}||^2 \\text{.}$$\n",
    "\n",
    "The following theorem gives us both a conceptual and a computational answer to this question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc995bdc",
   "metadata": {},
   "source": [
    "##### Theorem\n",
    "$\\displaystyle{J=\\frac{1}{N}\\cdot \\sum_{i=1}^N||x_i-\\hat{x_i}||^2=\\sum_{j=m+1}^Fb_j^TSb_j=\\text{trace}(BB^TS)}$, where $S$ is the covariance matrix for $\\mathcal{D}$ and $B=(b_{m+1} |b_{m+2} |...|b_D)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965de9fc",
   "metadata": {},
   "source": [
    "We now set about to verify this result in many special cases.  A formal proof can be found [here](https://www.coursera.org/learn/pca-machine-learning/lecture/d8Nym/reformulation-of-the-objective).\n",
    "\n",
    "To this end, the following three functions implement each of the equal expressions in the above Theorem.\n",
    "\n",
    "The function reconstructError implements $\\displaystyle{\\frac{1}{N}\\cdot \\sum_{i=1}^N||x_i-\\hat{x_i}||^2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f6797ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructError(data, B, m):\n",
    "    \"\"\"Compute the average squared reconstruction error that results from the orthogonal projection of each row of data \n",
    "        onto the subspace spanned by the columns of B.\n",
    "        Args: \n",
    "            data: matrix of shape (N,F) representing the MEAN CENTERED data\n",
    "            B: Matrix whose columns form an orthonormal basis for R^F\n",
    "            m: the number of basis vectors to use\n",
    "            \n",
    "        Returns: Average squared reconstruction error\"\"\"\n",
    "    \n",
    "    N=data.shape[0]\n",
    "    X=data.T\n",
    "    B=B[:,:m]\n",
    "    # Compute XHat \n",
    "    XHat=(B@B.T)@X\n",
    "    return (np.linalg.norm(X-XHat, axis=0)**2).sum()/N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698a83f9",
   "metadata": {},
   "source": [
    "The function compEquiv1 implements $\\displaystyle{\\sum_{j=m+1}^Fb_j^TSb_j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6ecf4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compEquiv1(data, B, m):\n",
    "    \"\"\"Compute the sum(bj^T*S*b_j) from j=m+1 to F\n",
    "        Args: \n",
    "            data: matrix of shape (N,D) representing the MEAN CENTERED data\n",
    "            B: Matrix whose columns form an orthonormal basis for R^D\n",
    "            m: the number of basis vectors to use\n",
    "            \n",
    "        Returns: sum(bj^T*S*b_j) from j=m+1 to F\"\"\"    \n",
    "    S=cov(data)\n",
    "    B=B[:,m:]\n",
    "    return np.trace(B.T@S@B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf529f77",
   "metadata": {},
   "source": [
    "The function compEquiv2 implements $\\displaystyle{\\text{trace}(BB^TS)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "873eba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compEquiv2(data, B, m):\n",
    "    \"\"\"Compute trace(BB^TS), where B=B[:, m:]\n",
    "        Args: \n",
    "            data: matrix of shape (N,F) representing the MEAN CENTERED data\n",
    "            B: Matrix whose columns form an orthonormal basis for R^F\n",
    "            m: the number of basis vectors to use\n",
    "            \n",
    "        Returns: trace(BB^TS), where B=B[:, m:]\"\"\"    \n",
    "    S=cov(data)\n",
    "    B=B[:,m:]\n",
    "    return np.trace(B@B.T@S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12e106",
   "metadata": {},
   "source": [
    "##### Example\n",
    "\n",
    "The code below gives $100$ examples that verify the theorem above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cfbd3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "numNotEquiv=0\n",
    "N=2000\n",
    "for i in range(100):\n",
    "    numFeatures=np.random.randint(low=10,high=101)\n",
    "    numIgnored=np.random.randint(low=5,high=numFeatures-4)\n",
    "    D,_=normalize(np.random.randn(N,numFeatures))\n",
    "    S=randSym(numFeatures)\n",
    "    eigvals, B = eig(S)\n",
    "    # Check that columns of B form orthonormal basis \n",
    "    if (np.allclose(B.T@B, np.eye(numFeatures),atol=1e-10)) and (matrix_rank(B, hermitian=True)==numFeatures):\n",
    "        if not(np.allclose(reconstructError(D,B,numFeatures-numIgnored), compEquiv1(D,B,numFeatures-numIgnored))) or not(np.allclose(reconstructError(D,B,numFeatures-numIgnored), compEquiv2(D,B,numFeatures-numIgnored))):\n",
    "            numNotEquiv+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "96c0a0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numNotEquiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72994f0",
   "metadata": {},
   "source": [
    "$\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06201c39",
   "metadata": {},
   "source": [
    "Recall that our goal is to use our now established fact that \n",
    "\n",
    "$\\displaystyle{J=\\frac{1}{N}\\cdot \\sum_{i=1}^N||x_i-\\hat{x_i}||^2=\\sum_{j=m+1}^Fb_j^TSb_j=\\text{trace}(BB^TS)}$, where $S$ is the covariance matrix for $\\mathcal{D}$ and $B=(b_{m+1} |b_{m+2} |...|b_D)$\n",
    "\n",
    "to give both a conceptual and computational answer to the question:\n",
    "\n",
    "##### How much information is lost when all $x_i$ are projected onto U?\n",
    "\n",
    "First, the conceptual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb722e4d",
   "metadata": {},
   "source": [
    "Consider $\\displaystyle{J=\\frac{1}{N}\\cdot \\sum_{i=1}^N||x_i-\\hat{x_i}||^2=\\text{trace}(BB^TS)}$, where $S$ is the covariance matrix for $\\mathcal{D}$ and $B=(b_{m+1} |b_{m+2} |...|b_D)$.  \n",
    "\n",
    "The projection $BB^TS$ projects the information contained in the covariance matrix $S$ into the *orthogonal complement* $U^{\\perp}$ of $U=span(b_1,b_2,...,b_m)$, the principal subspace.  Since the trace of a matrix is the sum along the main diagonal, the amount of information lost when all $x_i$ are projected onto $U$ is the amount of variance in the data that is stored in $U^{\\perp}$.\n",
    "\n",
    "Thus, to minimize $J$ we should choose $b_1,b_2,...,b_m$ to be the eigenvectors of $S$ that make $U=span(b_1,b_2,...,b_m)$ contain the most variance in the data.  The computational answer to our question will show us how to do this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcafe12",
   "metadata": {},
   "source": [
    "Now, the computational.\n",
    "\n",
    "Using the method of *Lagrange Multipliers*, we will now find an explicit formula for $\\displaystyle{J=\\frac{1}{N}\\cdot \\sum_{i=1}^N||x_i-\\hat{x_i}||^2}$ consisting of eigenvalues of $S$.  Instead of a fully general derivation, we give an example that the reader can generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f03bab",
   "metadata": {},
   "source": [
    "##### Example\n",
    "\n",
    "Suppose that we have a data set $\\mathcal{D}\\in \\mathbb{R}^{N \\times 4}$.  Then, $S=cov(\\mathcal{D})$ is a $4 \\times 4$ symmetric matrix.  By the Spectral Theorem, we are guarenteed that an orthonormal basis $b_1,b_2,b_3,b_4$ for $\\mathbb{R}^4$ consisting of eigenvalues of $S$ exists.\n",
    "\n",
    "Further suppose that we have projected our data set onto $U=span(b_1,b_2)$.\n",
    "\n",
    "Then, $\\displaystyle{J=\\frac{1}{N}\\cdot \\sum_{i=1}^N||x_i-\\hat{x_i}||^2=\\sum_{j=3}^4b_j^TSb_j}=b_3^TSb_3+b_4^TSb_4$.  We seek to minimize $J$ under the constraints $b_3^Tb_3=1$ and $b_4^Tb_4=1$.\n",
    "\n",
    "The Lagrangian is $L=b_3^TSb_3+b_4^TSb_4+\\lambda_3(1-b_3^Tb_3)+\\lambda_4(1-b_4^Tb_4)$.\n",
    "\n",
    "For $i=3$ or $4$, $\\frac{\\partial L}{\\partial \\lambda_i}=1-b_i^Tb_i=0\\Leftrightarrow b_i^Tb_i=1$, recovering our constraints.\n",
    "\n",
    "For $i=3$ or $4$, $\\frac{\\partial L}{\\partial b_i}=\\frac{\\partial}{\\partial b_i}(b_i^TSb_i)+\\frac{\\partial}{\\partial b_i}(\\lambda_i(b_i^Tb_i-1))$.\n",
    "\n",
    "Theorem: If $x$ is $n\\times 1$, $A$ is $n \\times n$, and $A$ does not depend on $x$, then $\\frac{\\partial}{\\partial x}(x^TAX)=x^T(A+A^T)$.\n",
    "\n",
    "Using the above theorem and the fact that both $S=cov($data$)$ and the identity matrix are symmetric, we have \n",
    "\n",
    "$\\frac{\\partial}{\\partial b_i}(b_i^TSb_i)=b_i^T(S+S^T)=2b_i^TS$ and similarly, $\\frac{\\partial}{\\partial b_i}(\\lambda_i(b_i^Tb_i-1))=2\\lambda_ib_i^T$. \n",
    "\n",
    "Thus, for $i=3$ or $4$, $\\frac{\\partial L}{\\partial b_i}=2b_i^TS-2\\lambda_ib_i^T=0 \\Leftrightarrow 2b_i^TS=2\\lambda_ib_i^T$.\n",
    "\n",
    "Multiplying this last equality first on the left and then on the right by $b_i$ and dividing by $2$ we obtain $Sb_i=\\lambda_ib_i$.  \n",
    "\n",
    "Thus, $J=b_3^TSb_3+b_4^TSb_4=b_3^T\\lambda_3b_3+b_4^T\\lambda_4b_4=\\lambda_3b_3^Tb_3+\\lambda_4b_4^Tb_4=\\lambda_3+\\lambda_4$.\n",
    "\n",
    "So, the amount of information lost in the projection of our data set onto $U$ is $\\lambda_3+\\lambda_4$, where $\\lambda_3$ and $\\lambda_4$ are eigenvalues of the covariance matrix of our data set.  $\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e8d3f",
   "metadata": {},
   "source": [
    "Generalizing the above example gives the following theorem.\n",
    "\n",
    "##### Theorem\n",
    "$\\displaystyle{J=\\frac{1}{N}\\cdot \\sum_{i=1}^N||x_i-\\hat{x_i}||^2=\\lambda_{m+1}+\\lambda_{m+2}+...+\\lambda_F}$, where $\\lambda_{m+1},\\lambda_{m+2},...,\\lambda_F$ are the eigenvalues that correspond with the eigenvectors $b_{m+1},b_{m+2},...,b_F$, respectively, of the covariance matrix $S$ of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41609f9",
   "metadata": {},
   "source": [
    "### Principal Component Analysis\n",
    "\n",
    "Using the above theorem, we see that the way to project a data set $\\mathcal{D}\\in \\mathbb{R}^{N \\times F}$ onto a lower dimensional subspace of $\\mathbb{R}^F$ and still preserve as much information (variance) in the data is to choose the eigenvectors $b_1,b_2,...,b_m$ of the covariance matrix $S=cov(\\mathcal{D})$ that correspond to the $m$ largest eigenvalues of $S$.\n",
    "\n",
    "Then, according to the theorem above, $\\displaystyle{J=\\lambda_{m+1}+\\lambda_{m+2}+...+\\lambda_F}$ will attain its minimum value, since $\\lambda_{m+1},\\lambda_{m+2},...,\\lambda_F$ are as small as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fc265316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_matrix(B):\n",
    "    \"\"\"Compute the projection matrix onto the space spanned by `B`\n",
    "    Args:\n",
    "        B: ndarray of dimension (F, M), the basis for the subspace\n",
    "    \n",
    "    Returns:\n",
    "        P: the projection matrix\n",
    "    \"\"\"\n",
    "\n",
    "    P=B@np.linalg.inv(B.T@B)@B.T\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "56a0cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(data, m):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data: ndarray of size (N, F), where F is the dimension of the data,\n",
    "           and N is the number of datapoints\n",
    "        m: the number of principal components to use.\n",
    "    Returns:\n",
    "        the reconstructed data, the sample mean of the X, principal values\n",
    "        and principal components\n",
    "    \"\"\"\n",
    "    \n",
    "    N=data.shape[0]\n",
    "    # Normalize the data \n",
    "    data_bar, mu = normalize(data)\n",
    "    X=data_bar.T\n",
    "    # Compute covariance matrix S \n",
    "    S=X@X.T/N\n",
    "    # Get principal vectors \n",
    "    eigVals, eigVecs = eig(S)\n",
    "    prinVals=eigVals[:m]\n",
    "    prinVecs=np.real(eigVecs[:, :m])\n",
    "    # Project the data \n",
    "    P=projection_matrix(prinVecs)\n",
    "    data_bar_prime=(P@X).T\n",
    "    # Recover the original data\n",
    "    data=data_bar_prime+mu\n",
    "\n",
    "    return data, mu, prinVals, prinVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f2986",
   "metadata": {},
   "source": [
    "##### Example\n",
    "We now compare our PCA algorithm to Sci-Kit Learn's PCA algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6ed487d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference in reconstruction for num_components = 1: 4.572492438673757e-27\n",
      "difference in reconstruction for num_components = 2: 1.700401380024597e-26\n",
      "difference in reconstruction for num_components = 3: 5.297477818951538e-27\n",
      "difference in reconstruction for num_components = 4: 5.2247668496471876e-27\n",
      "difference in reconstruction for num_components = 5: 1.753880391981476e-25\n",
      "difference in reconstruction for num_components = 6: 4.726459391407963e-27\n",
      "difference in reconstruction for num_components = 7: 3.514599643412818e-27\n",
      "difference in reconstruction for num_components = 8: 1.3238083846412833e-25\n"
     ]
    }
   ],
   "source": [
    "random = np.random.RandomState(0)\n",
    "data = random.randn(100, 10)\n",
    "\n",
    "from sklearn.decomposition import PCA as SKPCA\n",
    "\n",
    "for num_component in range(1, 9):\n",
    "    pca = SKPCA(n_components=num_component, svd_solver=\"full\")\n",
    "    sklearn_reconst = pca.inverse_transform(pca.fit_transform(data))\n",
    "    reconst,_,_,_ = PCA(data, num_component)\n",
    "    print(\n",
    "        \"difference in reconstruction for num_components = {}: {}\".format(\n",
    "            num_component, np.square(reconst - sklearn_reconst).sum()\n",
    "        )\n",
    "    )\n",
    "    np.allclose(reconst, sklearn_reconst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4820ffa",
   "metadata": {},
   "source": [
    "$\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b84060",
   "metadata": {},
   "source": [
    "##### Example\n",
    "We give a visualization of PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f5b1e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mvn = scipy.stats.multivariate_normal(\n",
    "    mean=np.array([1, 1]), \n",
    "    cov=np.array([[1, -0.8], [-0.8, 1]])\n",
    ")\n",
    "\n",
    "# data contains 200 points generated according to the above criteria\n",
    "data = mvn.rvs((200,), random_state=np.random.RandomState(0))\n",
    "\n",
    "num_components = 1\n",
    "data_reconst, mean, principal_values, principal_components = PCA(data, num_components)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(data[:, 0], data[:, 1], label='data')\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "ax.set(xlabel='$\\mathbf{x}_0$', ylabel='$\\mathbf{x}_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2323673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vector(v0, v1, ax=None, label=None):\n",
    "    \"\"\"Draw a vector from v0 to v1.\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0, \n",
    "                    color='k')\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8cacda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(data[:, 0], data[:, 1], label='data')\n",
    "for (princial_variance, principal_component) in (zip(principal_values, principal_components.T)):\n",
    "    draw_vector(\n",
    "        mean, mean + np.sqrt(princial_variance) * principal_component, \n",
    "        ax=ax)\n",
    "ax.scatter(data_reconst[:, 0], data_reconst[:, 1], label='reconstructed')\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "ax.set(xlabel='$\\mathbf{x}_0$', ylabel='$\\mathbf{x}_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8091c9d8",
   "metadata": {},
   "source": [
    "$\\Box$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62242ef",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "The PCA algorithm given herein is excellent for building intuition about PCA.  However, it is much less practical when compared to other implementations that use the Singular Value Decomposition (SVD).  \n",
    "\n",
    "This is because the implementation given in this notebook does not reduce the size of the data set.  The data is projected onto a lower dimensional subspace, but still has $F$ features.  Implementations using the SVD actually reduce the size of the data set lending the reduced data set to quicker application of Machine Learning algorithms and ease in data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1a8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
